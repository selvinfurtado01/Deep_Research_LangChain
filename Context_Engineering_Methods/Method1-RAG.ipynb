{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030f99c9",
   "metadata": {},
   "source": [
    "## RAG using LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251ff2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Downloading beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "\n",
      "   ---------------------------------------- 0/2 [soupsieve]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   ---------------------------------------- 2/2 [beautifulsoup4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.5 soupsieve-2.8\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a77a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "## Using OpenAI/Thinking Machine Lab Lilian Weng's blog posts\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2025-05-01-thinking/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\",\n",
    "]\n",
    "\n",
    "## Load documents from each URL into docs object\n",
    "docs = [WebBaseLoader(url).load() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95691b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "## Flatten (Wide-format) the list of documents\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "## Initialize text splitter and specify chuck_size and chunk_overlap\n",
    "## For RAG we want to separate the information in the docs into blocks(chunks)\n",
    "## Then retrieve those blocks in context based on semantic similarity\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=2000, \n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "## Split documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546eff5",
   "metadata": {},
   "source": [
    "### Semantic Similarity\n",
    "- It measures how closely two pieces of text or concepts are related in meaning, focusing on underlying ideas rather than just word-for-word matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ead7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import init_embeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "## Initialize embeddings model\n",
    "# providers = {\"mistralai\": \"langchain_mistralai\"}\n",
    "embeddings = init_embeddings(\"ollama:mistral:7b\")\n",
    "\n",
    "## Create in memory vector store from documents\n",
    "## This will live in memory and store these chunks for context\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=doc_splits, \n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "## Create retriever from vector store >> Retrieves information from Memory VectorStore\n",
    "## 4 types of blog posts stored so it is important to store them separately\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf87a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results are a list of Document objects and checking type for verification\n",
    "r = retriever.invoke(\"types of reward hacking\")\n",
    "print(type(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from utils import format_retriever_results\n",
    "\n",
    "## Create retriever tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\", ## tool name\n",
    "    \"Search and return information about Lilian Weng blog posts.\", ## tool description\n",
    ")\n",
    "\n",
    "## Test the retriever tool\n",
    "result = retriever_tool.invoke({\"query\": \"types of reward hacking\"})\n",
    "format_retriever_results(result[10:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a20f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "## Initialize language model\n",
    "llm = init_chat_model(\"ollama:mistral:7b\", temperature=0)\n",
    "\n",
    "## Bind the tools\n",
    "tools = [retriever_tool]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "## Bind tools to LLM for agent functionality\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import SystemMessage, ToolMessage\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "\n",
    "## Define the RAG agent system prompt\n",
    "rag_prompt = \"\"\"You are a helpful assistant tasked with retrieving information from a series of technical blog posts by Lilian Weng. \n",
    "Clarify the scope of research with the user before using your retrieval tool to gather context. Reflect on any context you fetch, and\n",
    "proceed until you have sufficient context to answer the user's research request.\"\"\"\n",
    "\n",
    "\n",
    "## Define the Nodes\n",
    "def llm_call(state: MessagesState) -> dict:\n",
    "    \"\"\"LLM decides whether to call a tool or not.\n",
    "    \n",
    "    Args:\n",
    "        state: Current conversation state\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with new messages\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [SystemMessage(content=rag_prompt)] + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "def tool_node(state: MessagesState) -> dict:\n",
    "    \"\"\"Performs the tool call.\n",
    "    \n",
    "    Args:\n",
    "        state: Current conversation state with tool calls\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with tool results\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", \"__end__\"]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call.\n",
    "    \n",
    "    Args:\n",
    "        state: Current conversation state\n",
    "        \n",
    "    Returns:\n",
    "        Next node to execute\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb502f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "## Add the Nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "## Add Edges to connect Nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool_node\": \"tool_node\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "## Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "## Display the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1500fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Invoke the Agent\n",
    "from utils import format_messages\n",
    "\n",
    "## Execute the RAG agent\n",
    "query = \"What are the types of reward hacking discussed in the blogs?\"\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "\n",
    "## Format and display results\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40e9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664ea0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19c9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff5184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a401ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b95976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63976a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f18950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dac709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4c572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ee4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648f6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956e92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03efec1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90957312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45365463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72284b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
