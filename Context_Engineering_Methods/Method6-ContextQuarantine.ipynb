{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c9b171",
   "metadata": {},
   "source": [
    "## Context Quarantine Using LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import langchain and langgraph modules and setup\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fae50",
   "metadata": {},
   "source": [
    "### Context Quarantine Constraint\n",
    "- Constraint: Information Co-ordination\n",
    "    - Here as multiple agents are being used it is important to create a system where information co-ordinated or passed betweeen these mutliple agents is coherent and intact and there is no loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fb3fc",
   "metadata": {},
   "source": [
    "### Structure:\n",
    "- Using a Supervisor Architecture for the Context Quarantine Method\n",
    "- Structure: Input >> Supervisor Agent >> [Delegates tasks] >> Math Agent/Web Search Agent >> Supervisor Agent >> END\n",
    "\n",
    "- Constraints in Multi-Agent System:\n",
    "    - When you are using a Multi-Agent system and more than one agent is able to write into the final decision then this can lead to conflicts between different agents due to opposing viewpoints as they are working independently\n",
    "\n",
    "    - In this case, if you need to use Multi-Agent System then limit the Multiple Agents to information gathering rather than decision-making and let a final agent make a decision, in this case only one agent will be responsible for the final decision and can perform de-conflicts among the other agents and this will not introduce conflicts.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6143c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = init_chat_model(\"ollama:mistral:7b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mathematical utility functions\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\n",
    "    \n",
    "    Args:\n",
    "        a: First number to add\n",
    "        b: Second number to add\n",
    "        \n",
    "    Returns:\n",
    "        Sum of the two numbers\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\n",
    "    \n",
    "    Args:\n",
    "        a: First number to multiply\n",
    "        b: Second number to multiply\n",
    "        \n",
    "    Returns:\n",
    "        Product of the two numbers\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "## Sample data retrieval function\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Mock web search function that returns FAANG company headcounts.\n",
    "    \n",
    "    In a real implementation, this would perform actual web searches.\n",
    "    Currently returns static 2024 data for demonstration purposes.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string (sample provided for this mock implementation)\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string with FAANG company employee headcounts\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"Here are the headcounts for each of the FAANG companies in 2024:\\n\"\n",
    "        \"1. **Facebook (Meta)**: 67,317 employees.\\n\"\n",
    "        \"2. **Apple**: 164,000 employees.\\n\"\n",
    "        \"3. **Amazon**: 1,551,000 employees.\\n\"\n",
    "        \"4. **Netflix**: 14,000 employees.\\n\"\n",
    "        \"5. **Google (Alphabet)**: 181,269 employees.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419de15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Improved agent prompts with clear role definitions and constraints\n",
    "\n",
    "## Agent 1: Math Function Agent\n",
    "math_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[add, multiply],\n",
    "    name=\"math_expert\",\n",
    "    prompt=\"\"\"You are a specialized mathematics expert with access to addition and multiplication tools.\n",
    "\n",
    "Your responsibilities:\n",
    "- Solve mathematical problems using the available tools\n",
    "- Always use tools for calculations rather than computing mentally\n",
    "- Use one tool at a time and show your work clearly\n",
    "- Focus exclusively on mathematical computations\n",
    "\n",
    "Constraints:\n",
    "- Do NOT attempt research, web searches, or data gathering\n",
    "- Do NOT perform calculations without using the provided tools\n",
    "- Always explain your mathematical reasoning step by step\"\"\"\n",
    ")\n",
    "\n",
    "## Agent 2: Web Search Agent\n",
    "research_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[web_search],\n",
    "    name=\"research_expert\",  \n",
    "    prompt=\"\"\"You are a specialized research expert with access to web search capabilities.\n",
    "\n",
    "Your responsibilities:\n",
    "- Find and retrieve factual information using web search\n",
    "- Provide comprehensive, well-sourced answers to research questions\n",
    "- Focus on data gathering and information synthesis\n",
    "\n",
    "Constraints:\n",
    "- Do NOT perform mathematical calculations or computations\n",
    "- Do NOT attempt to solve math problems - delegate those to the math expert\n",
    "- Always use your search tool to find current, accurate information\n",
    "- Present findings clearly and cite sources when available\"\"\"\n",
    ")\n",
    "\n",
    "## Supervisor Agent: Delegate tasks based on user request\n",
    "## Enhanced supervisor prompt with clear delegation strategy\n",
    "supervisor_prompt = \"\"\"You are an intelligent team supervisor managing two specialized experts: a research expert and a math expert.\n",
    "\n",
    "Your role is to:\n",
    "1. Analyze incoming requests to determine the required expertise\n",
    "2. Delegate tasks to the appropriate specialist\n",
    "3. Coordinate between agents when tasks require multiple skills\n",
    "4. Synthesize results from multiple agents when necessary\n",
    "\n",
    "Delegation Rules:\n",
    "- For data gathering, company information, current events, or factual research → use research_agent\n",
    "- For calculations, mathematical operations, or numerical analysis → use math_agent  \n",
    "- For complex tasks requiring both research and math → delegate sequentially (research first, then math)\n",
    "\n",
    "Important: You are a coordinator, not a doer. Always delegate work to your specialists rather than attempting tasks yourself. Never perform calculations or research directly.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create supervisor workflow for coordinating agents\n",
    "workflow = create_supervisor(\n",
    "    [research_agent, math_agent],\n",
    "    model=llm,\n",
    "    prompt=supervisor_prompt\n",
    ")\n",
    "\n",
    "## Compile the multi-agent application and display the application\n",
    "app = workflow.compile()\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36356ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Invoke the Agent\n",
    "from utils import format_messages\n",
    "query = \"what's the combined headcount of the FAANG companies in 2024?\"\n",
    "result = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c1ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cea4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc299fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fefdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f2e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21092ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7579863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789d7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec95aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab485457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f3680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce5ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b4368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78973a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab8c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03707b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef34d92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
