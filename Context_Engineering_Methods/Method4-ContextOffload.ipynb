{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efebc4d",
   "metadata": {},
   "source": [
    "## Context Offloading using LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import standard library, third-party packages\n",
    "import getpass\n",
    "import os\n",
    "from typing_extensions import Literal\n",
    "\n",
    "## Jupyter and display utilities  \n",
    "from IPython.display import Image, display\n",
    "\n",
    "## Pydantic for data modeling\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "## LangChain core components\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "## LangGraph components for workflow and state management\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the Environment Variables and Tools\n",
    "\n",
    "def _set_env(var: str) -> None:\n",
    "    \"\"\"Set environment variable if not already set.\n",
    "    \n",
    "    Args:\n",
    "        var: Environment variable name to set\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# Extended state class to include scratchpad functionality\n",
    "class ScratchpadState(MessagesState):\n",
    "    \"\"\"State that extends MessagesState to include a scratchpad field.\n",
    "    \n",
    "    The scratchpad provides temporary storage during agent execution,\n",
    "    allowing information to persist within a single conversation thread.\n",
    "    \"\"\"\n",
    "    scratchpad: str = Field(description=\"The scratchpad for storing notes\")\n",
    "\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Scratchpad management tools\n",
    "@tool\n",
    "class WriteToScratchpad(BaseModel):\n",
    "    \"\"\"Save notes to the scratchpad for future reference within the conversation.\"\"\"\n",
    "    notes: str = Field(description=\"Notes to save to the scratchpad\")\n",
    "\n",
    "@tool  \n",
    "class ReadFromScratchpad(BaseModel):\n",
    "    \"\"\"Read previously saved notes from the scratchpad.\"\"\"\n",
    "    reasoning: str = Field(description=\"Reasoning for fetching notes from the scratchpad\")\n",
    "\n",
    "search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = init_chat_model(\"ollama:mistral:7b\", temperature=0)\n",
    "\n",
    "# Configure scratchpad tools\n",
    "tools = [ReadFromScratchpad, WriteToScratchpad, search_tool]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the Nodes\n",
    "\n",
    "## Enhanced research planning prompt with structured workflow\n",
    "scratchpad_prompt = \"\"\"You are a sophisticated research assistant with access to web search and a persistent scratchpad for note-taking.\n",
    "\n",
    "Your Research Workflow:\n",
    "1. **Check Scratchpad**: Before starting a new research task, check your scratchpad to see if you have any relevant information already saved and use this to help write your research plan\n",
    "2. **Create Research Plan**: Create a structured research plan\n",
    "3. **Write to Scratchpad**: Save the research plan and any important information to your scratchpad\n",
    "4. **Use Search**: Gather information using web search to address each aspect of your research plan\n",
    "5. **Update Scratchpad**: After each search, update your scratchpad with new findings and insights\n",
    "5. **Iterate**: Repeat searching and updating until you have comprehensive information\n",
    "6. **Complete Task**: Provide a thorough response based on your accumulated research\n",
    "\n",
    "Tools Available:\n",
    "- WriteToScratchpad: Save research plans, findings, and progress updates\n",
    "- ReadFromScratchpad: Retrieve previous research work and notes\n",
    "- TavilySearch: Search the web for current information\n",
    "\n",
    "Always maintain organized notes in your scratchpad and build upon previous research systematically.\"\"\"\n",
    "\n",
    "def llm_call(state: ScratchpadState) -> dict:\n",
    "    \"\"\"Execute LLM call with system prompt and conversation history.\n",
    "    \n",
    "    Args:\n",
    "        state: Current conversation state\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with LLM response\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [SystemMessage(content=scratchpad_prompt)] + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "def tool_node(state: ScratchpadState) -> dict:\n",
    "    \"\"\"Execute tool calls and manage scratchpad state updates.\n",
    "    \n",
    "    Handles both reading from and writing to the scratchpad, updating\n",
    "    the conversation state accordingly.\n",
    "    \n",
    "    Args:\n",
    "        state: Current conversation state with tool calls\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with tool results and updated state\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        if tool_call[\"name\"] == \"WriteToScratchpad\":\n",
    "            ## Save notes to scratchpad and update state\n",
    "            notes = observation.notes\n",
    "            result.append(ToolMessage(content=f\"Wrote to scratchpad: {notes}\", tool_call_id=tool_call[\"id\"]))\n",
    "            update = {\"messages\": result, \"scratchpad\": notes}\n",
    "        elif tool_call[\"name\"] == \"ReadFromScratchpad\":\n",
    "            ## Retrieve notes from scratchpad state\n",
    "            notes = state.get(\"scratchpad\", \"\")\n",
    "            result.append(ToolMessage(content=f\"Notes from scratchpad: {notes}\", tool_call_id=tool_call[\"id\"]))\n",
    "            update = {\"messages\": result}\n",
    "        elif tool_call[\"name\"] == \"tavily_search\":\n",
    "            ## Write search tool observation to messages\n",
    "            result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "            update = {\"messages\": result}\n",
    "    return update\n",
    "\n",
    "def should_continue(state: ScratchpadState) -> Literal[\"tool_node\", \"__end__\"]:\n",
    "    \"\"\"Determine workflow continuation based on tool calls.\n",
    "    \n",
    "    Args:\n",
    "        state: Current conversation state\n",
    "        \n",
    "    Returns:\n",
    "        Next node name or END\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    return \"tool_node\" if last_message.tool_calls else END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the scratchpad workflow\n",
    "agent_builder = StateGraph(ScratchpadState)\n",
    "\n",
    "## Add the Nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "## Define the edges\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\"llm_call\", should_continue, {\"tool_node\": \"tool_node\", END: END})\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "## Display the workflow \n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Invoke the Agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "query = \"Compare the funding rounds and recent developments of Commonwealth Fusion Systems vs Helion Energy.\"\n",
    "state = agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "\n",
    "from utils import format_messages\n",
    "format_messages(state['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b985e",
   "metadata": {},
   "source": [
    "### Data Persistence\n",
    "\n",
    "- In this above example we are storing the Context: Research plan in a Scratchpad that is enabled using the state object that persists throughout the LLM Agent Process\n",
    "\n",
    "- However, this data will only be available throughout the lifecycle of the agent and would not be available post\n",
    "\n",
    "- Solution: InMemoryStore (Memory to Save Information)\n",
    "    - To Mitigate this and in case we want data to persist across different agent lifecycles so that we can use that data for tasks ahead or that another agent can access this data, we can use the InMemoryStore present in LangGraph\n",
    "\n",
    "    - This let's us save information in memory and can be accessed in different threads (different agent lifecycles) for complex tasks or in case we need this information to be fed to a new thread or agent in the process.\n",
    "\n",
    "    - For Production, this can be backed up to Redis/PostGreSQL for optimal data storage and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6b8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378b165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fefa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498aace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cecbd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da39dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe361e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478dbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f347df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8aeedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75302042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb48cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de493cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4953bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd25032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20592dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e419446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb7936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0703923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc8696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
