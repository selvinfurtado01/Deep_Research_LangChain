{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c0eb28",
   "metadata": {},
   "source": [
    "## Reseach Agent: MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9bb50",
   "metadata": {},
   "source": [
    "### MCP: Model Context Protocol\n",
    "\n",
    "- It is an open source Asychronous Client-Server protocol that is developed by Anthropic\n",
    "- It is an open-source standard for connecting AI Applications to external systems (Connects Clients and Servers)\n",
    "- It is a protocol used to connect Clients (AI Agents) with external tools, prompts or context  \n",
    "\n",
    "### Structure: \n",
    "- Step 1:\n",
    "    - User >> [Research Request] >> MCP Client (AI Agent) >> [Spawns MCP Server Process] >> MCP Server\n",
    "- Step 2:\n",
    "    - MCP Server >> [Tool Meta Data] >> MCP Client (Agent) >> [Tool Call] >> MCP Server >> [Tool Feedback] >> MCP Client\n",
    "\n",
    "- Interaction between MCP Client and MCP Server\n",
    "- This interaction is in JSON-RPC over stdio transport and Asynchronous execution (concurrent tool calls)\n",
    "- Standard Input - Output RPC (Remote Procedure Call) call using JSON Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff62eb0",
   "metadata": {},
   "source": [
    "### MCP Adapters\n",
    "\n",
    "- It provides a seamless bridge between Model Context Protocols and External Ecosystems/Frameworks\n",
    "- In this case, it provides a bridge between the MCP Server and LangChain Framework\n",
    "\n",
    "### Features of MCP Servers:\n",
    "\n",
    "- 1. File Operations: It has strict access control over files and file system\n",
    "- 2. Directory Management: Enables dynamic permissions with directory management\n",
    "- 3. Search Capabilities: Searching across different directories\n",
    "- 4. Metadata Access: Meta Data for files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a7230d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Research Agent Instructions MCP</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You are a research assistant conducting research on the user's input topic using local files. For context,     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  today's date is {date}.                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Task&gt;</span>                                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Your job is to use file system tools to gather information from local research files.                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can use any of the tools provided to you to find and read files that help answer the research question.    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Task&gt;</span>                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Available Tools&gt;</span>                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to file system tools and thinking tools:                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **list_allowed_directories**: See what directories you can access                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **list_directory**: List files in directories                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **read_file**: Read individual files                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **read_multiple_files**: Read multiple files at once                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **search_files**: Find files containing specific content                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **think_tool**: For reflection and strategic planning during research                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **CRITICAL: Use think_tool after reading files to reflect on findings and plan next steps**                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Available Tools&gt;</span>                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Instructions&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Think like a human researcher with access to a document library. Follow these steps:                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Read the question carefully** - What specific information does the user need?                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Explore available files** - Use list_allowed_directories and list_directory to understand what's          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  available                                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **Identify relevant files** - Use search_files if needed to find documents matching the topic               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. **Read strategically** - Start with most relevant files, use read_multiple_files for efficiency             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. **After reading, pause and assess** - Do I have enough to answer? What's still missing?                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  6. **Stop when you can answer confidently** - Don't keep reading for perfection                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Instructions&gt;</span>                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Hard Limits&gt;</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **File Operation Budgets** (Prevent excessive file reading):                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Simple queries**: Use 3-4 file operations maximum                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Complex queries**: Use up to 6 file operations maximum                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Always stop**: After 6 file operations if you cannot find the right information                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Stop Immediately When**:                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You can answer the user's question comprehensively from the files                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You have comprehensive information from 3+ relevant files                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Your last 2 file reads contained similar information                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Hard Limits&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Show Your Thinking&gt;</span>                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  After reading files, use think_tool to analyze what you found:                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What key information did I find?                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What's missing?                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Do I have enough to answer the question comprehensively?                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Should I read more files or provide my answer?                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Always cite which files you used for your information                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Show Your Thinking&gt;</span>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mResearch Agent Instructions MCP\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You are a research assistant conducting research on the user's input topic using local files. For context,     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  today's date is {date}.                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Task>\u001b[0m                                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Your job is to use file system tools to gather information from local research files.                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can use any of the tools provided to you to find and read files that help answer the research question.    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Task>\u001b[0m                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Available Tools>\u001b[0m                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You have access to file system tools and thinking tools:                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **list_allowed_directories**: See what directories you can access                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **list_directory**: List files in directories                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **read_file**: Read individual files                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **read_multiple_files**: Read multiple files at once                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **search_files**: Find files containing specific content                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **think_tool**: For reflection and strategic planning during research                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **CRITICAL: Use think_tool after reading files to reflect on findings and plan next steps**                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Available Tools>\u001b[0m                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Instructions>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Think like a human researcher with access to a document library. Follow these steps:                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Read the question carefully** - What specific information does the user need?                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Explore available files** - Use list_allowed_directories and list_directory to understand what's          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  available                                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **Identify relevant files** - Use search_files if needed to find documents matching the topic               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. **Read strategically** - Start with most relevant files, use read_multiple_files for efficiency             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. **After reading, pause and assess** - Do I have enough to answer? What's still missing?                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  6. **Stop when you can answer confidently** - Don't keep reading for perfection                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Instructions>\u001b[0m                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Hard Limits>\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **File Operation Budgets** (Prevent excessive file reading):                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Simple queries**: Use 3-4 file operations maximum                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Complex queries**: Use up to 6 file operations maximum                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Always stop**: After 6 file operations if you cannot find the right information                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Stop Immediately When**:                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You can answer the user's question comprehensively from the files                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You have comprehensive information from 3+ relevant files                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Your last 2 file reads contained similar information                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Hard Limits>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Show Your Thinking>\u001b[0m                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  After reading files, use think_tool to analyze what you found:                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What key information did I find?                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What's missing?                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Do I have enough to answer the question comprehensively?                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Should I read more files or provide my answer?                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Always cite which files you used for your information                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Show Your Thinking>\u001b[0m                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Import Necessary Modules\n",
    "\n",
    "from research_utils import show_prompt\n",
    "from deep_research_prompts.prompts import research_agent_prompt_with_mcp\n",
    "show_prompt(research_agent_prompt_with_mcp, \"Research Agent Instructions MCP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b329509",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mcp_example.py\n",
    "\n",
    "## MCP Example\n",
    "## Install Langchain adapters module: ! pip install langchain_mcp_adapters\n",
    "\n",
    "import subprocess, os\n",
    "import asyncio\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "\n",
    "console = Console()\n",
    "\n",
    "## Path to your local docs\n",
    "sample_docs_path = os.path.abspath(\"./deep_research_files/\")\n",
    "console.print(f\"[bold blue]Sample docs path:[/bold blue] {sample_docs_path}\")\n",
    "\n",
    "if not os.path.exists(sample_docs_path):\n",
    "    console.print(\"[red]✗ Directory does not exist![/red]\")\n",
    "else:\n",
    "    console.print(f\"[green]✓ Directory exists with files:[/green] {os.listdir(sample_docs_path)}\")\n",
    "\n",
    "## Start MCP server as a subprocess\n",
    "console.print(Panel(\"[bold yellow]Starting MCP server...[/bold yellow]\", expand=False))\n",
    "\n",
    "server_proc = subprocess.Popen([\n",
    "    \"npx.cmd\", \"-y\", \"@modelcontextprotocol/server-filesystem\",\n",
    "    sample_docs_path,\n",
    "], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "\n",
    "print(\"Line-Error Debugging\")\n",
    "## Print logs for debugging\n",
    "for i in range(1):\n",
    "    print(f\"Line: {i}\")\n",
    "    line = server_proc.stderr.readline()\n",
    "    print(f\"Line: {line}\")\n",
    "    if not line:\n",
    "        break\n",
    "    print(\"[MCP Server]\", line.decode().strip())\n",
    "\n",
    "print(\"Debugging Completed\")\n",
    "\n",
    "\n",
    "## Configure MCP client to connect over WebSocket\n",
    "mcp_config = {\n",
    "    \"filesystem\": {\n",
    "        \"command\": \"npx.cmd\",\n",
    "        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sample_docs_path],\n",
    "        \"transport\": \"stdio\"\n",
    "    }\n",
    "}\n",
    "\n",
    "client = MultiServerMCPClient(mcp_config)\n",
    "console.print(\"[green]✓ MCP server process started![/green]\")\n",
    "\n",
    "## Wrap async code for Notebook\n",
    "async def run_client():\n",
    "    console.print(Panel(\"[bold yellow]Getting tools...[/bold yellow]\", expand=False))\n",
    "    tools = await client.get_tools()\n",
    "\n",
    "    ## Create table of tools\n",
    "    table = Table(title=\"Available MCP Tools\", show_header=True, header_style=\"bold magenta\")\n",
    "    table.add_column(\"Tool Name\", style=\"cyan\", width=25)\n",
    "    table.add_column(\"Description\", style=\"white\", width=80)\n",
    "\n",
    "    for tool in tools:\n",
    "        desc = tool.description[:77] + \"...\" if len(tool.description) > 80 else tool.description\n",
    "        table.add_row(tool.name, desc)\n",
    "\n",
    "    console.print(table)\n",
    "    console.print(f\"[bold green]✓ Retrieved {len(tools)} tools from MCP server[/bold green]\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run_client())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc872f",
   "metadata": {},
   "source": [
    "- Windows doesn't support the routing logic to obtain the stdio files displaying an Unsupported Error\n",
    "- Hence, I've ran the code on the terminal and displayed the output here \n",
    "- Above File Code Output:\n",
    "\n",
    "```\n",
    "✓ Directory exists with files: ['coffee_shops_toronto.md']\n",
    "╭────────────────────────╮\n",
    "│ Starting MCP server... │\n",
    "╰────────────────────────╯\n",
    "Line-Error Debugging\n",
    "Line: 0\n",
    "Line: b'Secure MCP Filesystem Server running on stdio\\n'\n",
    "[MCP Server] Secure MCP Filesystem Server running on stdio\n",
    "Debugging Completed\n",
    "✓ MCP server process started!\n",
    "╭──────────────────╮\n",
    "│ Getting tools... │\n",
    "╰──────────────────╯\n",
    "                                              Available MCP Tools                                               \n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃ Tool Name                 ┃ Description                                                                      ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│ read_file                 │ Read the complete contents of a file as text. DEPRECATED: Use read_text_file ... │\n",
    "│ read_text_file            │ Read the complete contents of a file from the file system as text. Handles va... │\n",
    "│ read_media_file           │ Read an image or audio file. Returns the base64 encoded data and MIME type. O... │\n",
    "│ read_multiple_files       │ Read the contents of multiple files simultaneously. This is more efficient th... │\n",
    "│ write_file                │ Create a new file or completely overwrite an existing file with new content. ... │\n",
    "│ edit_file                 │ Make line-based edits to a text file. Each edit replaces exact line sequences... │\n",
    "│ create_directory          │ Create a new directory or ensure a directory exists. Can create multiple nest... │\n",
    "│ list_directory            │ Get a detailed listing of all files and directories in a specified path. Resu... │\n",
    "│ list_directory_with_sizes │ Get a detailed listing of all files and directories in a specified path, incl... │\n",
    "│ directory_tree            │ Get a recursive tree view of files and directories as a JSON structure. Each ... │\n",
    "│ move_file                 │ Move or rename files and directories. Can move files between directories and ... │\n",
    "│ search_files              │ Recursively search for files and directories matching a pattern. Searches thr... │\n",
    "│ get_file_info             │ Retrieve detailed metadata about a file or directory. Returns comprehensive i... │\n",
    "│ list_allowed_directories  │ Returns the list of directories that this server is allowed to access. Subdir... │\n",
    "└───────────────────────────┴──────────────────────────────────────────────────────────────────────────────────┘\n",
    "✓ Retrieved 14 tools from MCP server\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832fcc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Display the Agent Workflow\n",
    "from IPython.display import Image, display\n",
    "from mcp_research_agent import mcp_agent\n",
    "\n",
    "# Display the agent\n",
    "display(Image(mcp_agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4715681",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile research_agent_mcp.py\n",
    "\n",
    "## This file MCP Research Agent Workflow (Configurations, Agent Nodes & Edges and Compiled Workflow)\n",
    "## Here, it is similar to the Research Agent Workflow only tools are bound using MCP Server Tools\n",
    "\n",
    "\"\"\"Research Agent with MCP Integration.\n",
    "\n",
    "This module implements a research agent that integrates with Model Context Protocol (MCP)\n",
    "servers to access tools and resources. The agent demonstrates how to use MCP filesystem\n",
    "server for local document research and analysis.\n",
    "\n",
    "Key features:\n",
    "- MCP server integration for tool access\n",
    "- Async operations for concurrent tool execution (required by MCP protocol)\n",
    "- Filesystem operations for local document research\n",
    "- Secure directory access with permission checking\n",
    "- Research compression for efficient processing\n",
    "- Lazy MCP client initialization for LangGraph Platform compatibility\n",
    "\"\"\"\n",
    "\n",
    "import os, subprocess\n",
    "from rich.console import Console\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage, filter_messages\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from research_utils import format_messages\n",
    "import asyncio\n",
    "from langchain_core.messages import HumanMessage\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "from deep_research_prompts.prompts import research_agent_prompt_with_mcp, compress_research_system_prompt, compress_research_human_message\n",
    "from state_research import ResearcherState, ResearcherOutputState\n",
    "from research_stage_prompt.prompts import get_today_str, think_tool, get_current_dir\n",
    "\n",
    "## CONFIGURATION\n",
    "\n",
    "## MCP server configuration for filesystem access\n",
    "## The MCP Client Configuration requires Command, Arguments and Transport to be defined\n",
    "## Command: Server executes locally as a process using the npx command\n",
    "\n",
    "console = Console()\n",
    "\n",
    "sample_docs_path = os.path.abspath(\"./deep_research_files/\")\n",
    "console.print(f\"[bold blue]Sample docs path:[/bold blue] {sample_docs_path}\")\n",
    "\n",
    "if not os.path.exists(sample_docs_path):\n",
    "    console.print(\"[red]✗ Directory does not exist![/red]\")\n",
    "else:\n",
    "    console.print(f\"[green]✓ Directory exists with files:[/green] {os.listdir(sample_docs_path)}\")\n",
    "\n",
    "server_proc = subprocess.Popen([\n",
    "    \"npx.cmd\", \"-y\", \"@modelcontextprotocol/server-filesystem\",\n",
    "    sample_docs_path,\n",
    "], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "print(\"Line-Error Debugging\")\n",
    "## Print logs for debugging\n",
    "for i in range(1):\n",
    "    print(f\"Line: {i}\")\n",
    "    line = server_proc.stderr.readline()\n",
    "    print(f\"Line: {line}\")\n",
    "    if not line:\n",
    "        break\n",
    "    print(\"[MCP Server]\", line.decode().strip())\n",
    "\n",
    "print(\"Debugging Completed\")\n",
    "\n",
    "\n",
    "mcp_config = {\n",
    "    \"filesystem\": {\n",
    "        \"command\": \"npx.cmd\",\n",
    "        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sample_docs_path],\n",
    "        \"transport\": \"stdio\"\n",
    "    }\n",
    "}\n",
    "\n",
    "## Global client variable - will be initialized lazily\n",
    "_client = None\n",
    "\n",
    "def get_mcp_client():\n",
    "    \"\"\"Get or initialize MCP client lazily to avoid issues with LangGraph Platform.\"\"\"\n",
    "    global _client\n",
    "    if _client is None:\n",
    "        _client = MultiServerMCPClient(mcp_config)\n",
    "    return _client\n",
    "\n",
    "## Initialize models\n",
    "compress_model = init_chat_model(model=\"ollama:granite3.3:8b\", max_tokens=32000)\n",
    "model = init_chat_model(model=\"ollama:llama3.1:8b\")\n",
    "\n",
    "## AGENT NODES\n",
    "\n",
    "async def llm_call(state: ResearcherState):\n",
    "    \"\"\"Analyze current state and decide on tool usage with MCP integration.\n",
    "\n",
    "    This node:\n",
    "    1. Retrieves available tools from MCP server\n",
    "    2. Binds tools to the language model\n",
    "    3. Processes user input and decides on tool usage\n",
    "\n",
    "    Returns updated state with model response.\n",
    "    \"\"\"\n",
    "    # Get available tools from MCP server\n",
    "    client = get_mcp_client()\n",
    "    mcp_tools = await client.get_tools()\n",
    "\n",
    "    # Use MCP tools for local document access\n",
    "    tools = mcp_tools + [think_tool]\n",
    "\n",
    "    # Initialize model with tool binding\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "    # Process user input with system prompt\n",
    "    return {\n",
    "        \"researcher_messages\": [\n",
    "            model_with_tools.invoke(\n",
    "                [SystemMessage(content=research_agent_prompt_with_mcp.format(date=get_today_str()))] + state[\"researcher_messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "async def tool_node(state: ResearcherState):\n",
    "    \"\"\"Execute tool calls using MCP tools.\n",
    "\n",
    "    This node:\n",
    "    1. Retrieves current tool calls from the last message\n",
    "    2. Executes all tool calls using async operations (required for MCP)\n",
    "    3. Returns formatted tool results\n",
    "\n",
    "    Note: MCP requires async operations due to inter-process communication\n",
    "    with the MCP server subprocess. This is unavoidable.\n",
    "    \"\"\"\n",
    "    tool_calls = state[\"researcher_messages\"][-1].tool_calls\n",
    "\n",
    "    async def execute_tools():\n",
    "        \"\"\"Execute all tool calls. MCP tools require async execution.\"\"\"\n",
    "        # Get fresh tool references from MCP server\n",
    "        client = get_mcp_client()\n",
    "        mcp_tools = await client.get_tools()\n",
    "        tools = mcp_tools + [think_tool]\n",
    "        tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "        # Execute tool calls (sequentially for reliability)\n",
    "        observations = []\n",
    "        for tool_call in tool_calls:\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            if tool_call[\"name\"] == \"think_tool\":\n",
    "                # think_tool is sync, use regular invoke\n",
    "                observation = tool.invoke(tool_call[\"args\"])\n",
    "            else:\n",
    "                # MCP tools are async, use ainvoke\n",
    "                observation = await tool.ainvoke(tool_call[\"args\"])\n",
    "            observations.append(observation)\n",
    "\n",
    "        # Format results as tool messages\n",
    "        tool_outputs = [\n",
    "            ToolMessage(\n",
    "                content=observation,\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "            for observation, tool_call in zip(observations, tool_calls)\n",
    "        ]\n",
    "\n",
    "        return tool_outputs\n",
    "\n",
    "    messages = await execute_tools()\n",
    "\n",
    "    return {\"researcher_messages\": messages}\n",
    "\n",
    "def compress_research(state: ResearcherState) -> dict:\n",
    "    \"\"\"Compress research findings into a concise summary.\n",
    "\n",
    "    Takes all the research messages and tool outputs and creates\n",
    "    a compressed summary suitable for further processing or reporting.\n",
    "\n",
    "    This function filters out think_tool calls and focuses on substantive\n",
    "    file-based research content from MCP tools.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = compress_research_system_prompt.format(date=get_today_str())\n",
    "    messages = [SystemMessage(content=system_message)] + state.get(\"researcher_messages\", []) + [HumanMessage(content=compress_research_human_message)]\n",
    "\n",
    "    response = compress_model.invoke(messages)\n",
    "\n",
    "    # Extract raw notes from tool and AI messages\n",
    "    raw_notes = [\n",
    "        str(m.content) for m in filter_messages(\n",
    "            state[\"researcher_messages\"], \n",
    "            include_types=[\"tool\", \"ai\"]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"compressed_research\": str(response.content),\n",
    "        \"raw_notes\": [\"\\n\".join(raw_notes)]\n",
    "    }\n",
    "\n",
    "## ROUTING LOGIC\n",
    "\n",
    "def should_continue(state: ResearcherState) -> Literal[\"tool_node\", \"compress_research\"]:\n",
    "    \"\"\"Determine whether to continue with tool execution or compress research.\n",
    "\n",
    "    Determines whether to continue with tool execution or compress research\n",
    "    based on whether the LLM made tool calls.\n",
    "    \"\"\"\n",
    "    messages = state[\"researcher_messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # Continue to tool execution if tools were called\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "    # Otherwise, compress research findings\n",
    "    return \"compress_research\"\n",
    "\n",
    "## GRAPH CONSTRUCTION: Agent Workflow\n",
    "\n",
    "## Build the agent workflow\n",
    "agent_builder_mcp = StateGraph(ResearcherState, output_schema=ResearcherOutputState)\n",
    "\n",
    "## Add nodes to the graph\n",
    "agent_builder_mcp.add_node(\"llm_call\", llm_call)\n",
    "agent_builder_mcp.add_node(\"tool_node\", tool_node)\n",
    "agent_builder_mcp.add_node(\"compress_research\", compress_research)\n",
    "\n",
    "## Add edges to connect nodes\n",
    "agent_builder_mcp.add_edge(START, \"llm_call\")\n",
    "agent_builder_mcp.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool_node\": \"tool_node\",        # Continue to tool execution\n",
    "        \"compress_research\": \"compress_research\",  # Compress research findings\n",
    "    },\n",
    ")\n",
    "agent_builder_mcp.add_edge(\"tool_node\", \"llm_call\")  # Loop back for more processing\n",
    "agent_builder_mcp.add_edge(\"compress_research\", END)\n",
    "\n",
    "## Compile the agent\n",
    "mcp_agent = agent_builder_mcp.compile()\n",
    "\n",
    "## Invoke the agent\n",
    "\n",
    "research_brief = \"\"\"I want to identify and evaluate the coffee shops in Toronto that are considered the best based specifically  \n",
    "on coffee quality. My research should focus on analyzing and comparing coffee shops within the Toronto area, \n",
    "using coffee quality as the primary criterion. I am open regarding methods of assessing coffee quality (e.g.,      \n",
    "expert reviews, customer ratings, specialty coffee certifications), and there are no constraints on ambiance,      \n",
    "location, wifi, or food options unless they directly impact perceived coffee quality. Please prioritize primary    \n",
    "sources such as the official websites of coffee shops, reputable third-party coffee review organizations (like     \n",
    "Coffee Review or Specialty Coffee Association), and prominent review aggregators like Google or Yelp where direct  \n",
    "customer feedback about coffee quality can be found. The study should result in a well-supported list or ranking of\n",
    "the top coffee shops in Toronto, emphasizing their coffee quality according to the latest available data as  \n",
    "of July 2025.\"\"\"\n",
    "\n",
    "async def mcp_agent_output():\n",
    "    result = await mcp_agent.ainvoke({\"researcher_messages\": [HumanMessage(content=f\"{research_brief}.\")]})\n",
    "    format_messages(result['researcher_messages'])\n",
    "    comp_markdn = Markdown(result[\"compressed_research\"])\n",
    "    console.print(\"[green]✓ Conpressed MarkDown:[/green]\")\n",
    "    console.print(comp_markdn)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(mcp_agent_output())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535020d",
   "metadata": {},
   "source": [
    "- Windows doesn't support the routing logic to obtain the stdio files displaying an Unsupported Error\n",
    "- Hence, I've ran the code on the terminal and displayed the output here \n",
    "- Above File Code Output:\n",
    "\n",
    "```\n",
    "✓ Directory exists with files: ['Toronto_Coffee_Shops.md']\n",
    "Line-Error Debugging\n",
    "Line: 0\n",
    "Line: b'Secure MCP Filesystem Server running on stdio\\n'\n",
    "[MCP Server] Secure MCP Filesystem Server running on stdio\n",
    "Debugging Completed\n",
    "╭────────────────────────────────────────────────────────────────── 🧑 Human ───────────────────────────────────────────────────────────────────╮\n",
    "│ I want to identify and evaluate the coffee shops in Toronto that are considered the best based specifically                                   │\n",
    "│ on coffee quality. My research should focus on analyzing and comparing coffee shops within the Toronto area,                                  │\n",
    "│ using coffee quality as the primary criterion. I am open regarding methods of assessing coffee quality (e.g.,                                 │\n",
    "│ expert reviews, customer ratings, specialty coffee certifications), and there are no constraints on ambiance,                                 │\n",
    "│ location, wifi, or food options unless they directly impact perceived coffee quality. Please prioritize primary                               │\n",
    "│ sources such as the official websites of coffee shops, reputable third-party coffee review organizations (like                                │\n",
    "│ Coffee Review or Specialty Coffee Association), and prominent review aggregators like Google or Yelp where direct                             │\n",
    "│ customer feedback about coffee quality can be found. The study should result in a well-supported list or ranking of                           │\n",
    "│ the top coffee shops in Toronto, emphasizing their coffee quality according to the latest available data as                                   │\n",
    "│ of July 2025..                                                                                                                                │\n",
    "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    "╭──────────────────────────────────────────────────────────────────── 📝 AI ────────────────────────────────────────────────────────────────────╮\n",
    "│ To answer your question using the provided functions, I will first use `list_allowed_directories` to identify accessible directories and then │\n",
    "│ use `search_files` with a pattern that matches relevant files within those directories.                                                       │\n",
    "│                                                                                                                                               │\n",
    "│ {\"name\": \"list_allowed_directories\", \"parameters\": {}}                                                                                        │\n",
    "│                                                                                                                                               │\n",
    "│ The next step is to search for files related to coffee shops in Toronto based on the given criteria.                                          │\n",
    "│                                                                                                                                               │\n",
    "│ However, since I don't have specific file names or paths initially, let's start by searching for key terms and phrases that might be present  │\n",
    "│ in relevant documents. We'll use `search_files` with a pattern that includes our research keywords.                                           │\n",
    "│                                                                                                                                               │\n",
    "│ {\"name\": \"search_files\", \"parameters\": {\"path\": \"/home/user/research/city_reviews/Toronto\", \"pattern\": \"coffee shop quality toronto best      │\n",
    "│ coffee reviews\"}}                                                                                                                             │\n",
    "│                                                                                                                                               │\n",
    "│ Given the complexity of this query, we will stop after three file operations as per the hard limits to ensure efficient use of our resources. │\n",
    "│                                                                                                                                               │\n",
    "│ After identifying potential files and directories, let's analyze them using `read_multiple_files` for efficiency. This function allows us to  │\n",
    "│ read multiple files at once while handling failed reads efficiently.                                                                          │\n",
    "│                                                                                                                                               │\n",
    "│ {\"name\": \"read_multiple_files\", \"parameters\": {\"paths\": [\"/home/user/research/city_reviews/Toronto/coffee_shops.pdf\",                         │\n",
    "│ \"/home/user/research/organizations/Coffee Review/coffee_mags.txt\"]}}                                                                          │\n",
    "│                                                                                                                                               │\n",
    "│ Once I've gathered this information, I'll reflect on my findings with `think_tool` to ensure that I have enough evidence to compile a         │\n",
    "│ comprehensive list of top coffee shops in Toronto based on their coffee quality.                                                              │\n",
    "│                                                                                                                                               │\n",
    "│ {\"name\": \"think_tool\", \"parameters\": {\"reflection\": \"I found several documents discussing coffee shop quality in Toronto. However, I need     │\n",
    "│ more information on expert reviews and customer ratings for a complete answer.\"}}                                                             │\n",
    "│                                                                                                                                               │\n",
    "│ To finalize my research, let's check if there are any other files that might be relevant to our analysis.                                     │\n",
    "│                                                                                                                                               │\n",
    "│ {\"name\": \"search_files\", \"parameters\": {\"path\": \"/home/user/research/city_reviews/Toronto\", \"pattern\": \"coffee shop quality expert reviews\"}} │\n",
    "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    "✓ Conpressed MarkDown:\n",
    "\n",
    "\n",
    " 1 The Score Coffee Roasters:\n",
    "    • Reviewed by various sources including Coffee Review which awarded them 90 points for their \"Ethiopia Sidamo, Yirgacheffe\" coffee, noting   \n",
    "      its floral and citrus notes ([source: 1]).\n",
    "    • Highly rated by customers on Google Reviews with mentions of high-quality coffee and roasting practices. Google Review\n",
    " 2 Square Mile Coffee Roasters:\n",
    "    • Awarded Gold Medal at the Canadian National Barista Championship 2024, indicating exceptional coffee quality ([source: 2]).\n",
    "    • Customers on Yelp commend their meticulous preparation and bean variety Yelp Review\n",
    " 3 Timothy’s Coffee:\n",
    "    • Well-established brand with multiple locations, recognized for consistency in quality across its stores ([source: 3]).\n",
    "    • Mixed customer feedback on Google and Yelp, some praising coffee quality, others mentioning variability. Google Review, Yelp Review        \n",
    " 4 Second Cup:\n",
    "    • Known for their “Fair Trade” commitment and variety in specialty coffees ([source: 4]).\n",
    "    • Customer feedback indicates a preference for their seasonal offerings on platforms like Yelp Yelp Review.\n",
    " 5 Balzac Brothers:\n",
    "    • Appreciated for its artisanal approach to coffee, offering single-origin brews and pour-over options ([source: 5]).\n",
    "    • Customers on Instagram highlight their unique blends and barista skills Instagram Post\n",
    "\n",
    "Additional Insights:\n",
    "\n",
    " • The Specialty Coffee Association (SCA) has listed several Toronto cafes that are SCA certified, indicating adherence to stringent quality     \n",
    "   standards ([source: 6]).\n",
    " • A 2024 report by the National Coffee Association of Canada emphasized Toronto's growing specialty coffee scene, with a particular mention of  \n",
    "   Score Coffee and Square Mile as leaders in quality. NCA Canada Report\n",
    "\n",
    "Reflections on Data Gaps: While several reputable sources and customer reviews provide insights into Toronto's coffee shops, there’s a noticeable\n",
    "gap concerning comprehensive expert ratings. SCA certification data is valuable but lacks granularity in per-shop quality metrics beyond\n",
    "certification itself.\n",
    "\n",
    "                                                                    Sources:\n",
    "\n",
    "[1] Coffee Review - Score Coffee Roasters Evaluation: http://www.coffeereview.com [2] Canadian National Barista Championship 2024 Results:       \n",
    "[Source not explicitly provided in the generated content, but assumed to be accessible from standard tournament archives or SCA Canada] [3]      \n",
    "Timothy’s Coffee Brand Reputation: http://www.timothys.com [4] Second Cup Commitment to Fair Trade: http://www.secondcup.com [5] Balzac Brothers \n",
    "Instagram Highlights Customer Experiences: https://www.instagram.com/balzacbrothers [6] SCA Toronto Certified Members List:\n",
    "https://sca.coffee/certification/find-a-member [NCA Canada Report]: [http://www.nca-canada.org/reports] - Assumed link, as specific report       \n",
    "details not provided in the generated content.</fully comprehensive findings>\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f698d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4ae5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8d95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260e922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f1248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18378e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596e3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa4756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a2349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d7f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
